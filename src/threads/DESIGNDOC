            +--------------------+
            |       CS 124       |
            | PROJECT 3: THREADS |
            |   DESIGN DOCUMENT  |
            +--------------------+
                   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Henry Elbaum  helbaum@caltech.edu
Kyle Seipp    kseipp@caltech.edu
Bianca Ray Avalani  brayaval@caltech.edu
>> Specify how many late tokens you are using on this assignment:  
1

>> What is the Git repository and commit hash for your submission?
   (You only need to include the commit-hash in the file you submit
   on Moodle.)

   Repository URL:  login.cms.caltech.edu:/cs/courses/cs124/teams/ComedicLuddites
   commit ...

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course instructors.

                  THREADS
                  =======

---- LOGISTICS ----

These questions will help us to keep track of the difficulty level of
assignments, as well as keeping track of which team members worked on
which parts.

>> L1: How many hours did each team member spend on this assignment?
   Make sure that each member's total time is listed.
   Henry Elbaum: 20
   Bianca: 
   Kyle: I don't want to count that high. 28 (Wish I was more efficient)

>> L2: What did each team member focus on for this assignment?  Keep
   descriptions to 25-30 words or less.
   Henry Elbaun: Alarm clock, priority donation
   Bianca Ray Avalani: Regular priority scheduling, helped with concurrency, locks, BSD debugging
   Kyle Seipp: BSD Scheduler, some work on interrupts, more debugging esp with BSD scheduler and some issues with lists

                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

thread_sleep in thread.c is called, which sets the wake_tick of the current
thread to the current tick plus the number of ticks to sleep. The current
thread is then put in timer_list, the list of processes blocked on the timer,
and then blocks.
The timer interrupt determines the current tick and then marches through
timer_list, checking if any processes need to wake up. Whenever it finds a 
process that needs to wake up, it moves it from timer_list to the appropriate
ready queue

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

thread_sleep calculates the time to wake up, so the timer interrupt doesn't
have to do extra steps of arithmetic. The timer interrupt figures out the
current tick only once so it doesn't have to do an extra call to get it with
each iteration throught the for loop. A list of sleeping threads is iterated
over rather than going through all threads and figuring out which is sleeping
at all

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

Interrupts are disabled in thread_sleep

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

Interrupts are disabled around the iteration through timer_list

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We considered using a countdown integer and then waking a thread when its
countdown is <= 0. But then I reread the slides and realized that was making
the timer do a little bit of extra computation. We also thought about having 
the iteration through timer_list happen outside of the timer interrupt somehow,
but I don't think that would actually help, since we'll be really sad if
anything interrupts the iteration, so interrupts ought be turned off, and then
there isn't really much advantage doing it outside of the timer handler

             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

We know which thread is highest because we have an arry of linked lists. They range from primin to primax. The threads are inserted into the linked list of the approppriate priority. Thus we look for the highest numbered linked list that is non empty. If all are empty, then we run the idle thread.


>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

Suppose we have a lock l. l has a field named donation, initialized to 0, 
keeping track of the highest priority among processes waiting on the lock. 
When a process P tries to acquire l when l is already held, then l.donation
is set to the max of itself and the priority of P. Let's call the process holding l Q.
Then if Q's priority is less than l.donation, then Q's priority is set to 
l.donation, resorting Q in the ready queues. Then the donation of the lock that Q is blocked on is set to Q's
priority, This is repeated (setting lock holder's priority to the max, and
setting the held locks donation) until a process is donated to and is not 
blocked on a lock.

After a thread acquires a lock, it puts that lock in its list of held locks.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

When a thread releases a lock, it removes the lock from its list of held
locks, and then determines which of the locks it still holds has the maximum
donation and uses that to redetermine its own priority. 

We know which thread is highest because we have an arry of linked lists. They range from primin to primax. The threads are inserted into the linked list of the approppriate priority. Thus we look for the highest numbered linked list that is non empty. If all are empty, then we run the idle thread.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

Locks 

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

              ADVANCED SCHEDULER
              ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
struct thread {
    /*! Owned by thread.c. */
    /**@{*/
    tid_t tid;                          /*!< Thread identifier. */
    enum thread_status status;          /*!< Thread state. */
    char name[16];                      /*!< Name (for debugging purposes). */
    uint8_t *stack;                     /*!< Saved stack pointer. */
    int priority;                       /*!< Priority (including donation). */
    int base_priority;                  /*!< Base priority. */
    int64_t wake_tick;                  /*!< Ticks left until it's time to wake up. */
    struct list_elem allelem;           /*!< List element for all threads list. */
    struct list_elem timer_elem;        /*!< List element for timer blocked list */
    int niceness;			/*!< Niceness value */
    int recent_cpu;                     /*!< Measure of how recently the function has had the CPU */
    /**@}*/

    struct list locks;                  /*!< List of locks this thread holds */
    struct lock *blocking_lock;         /*!< Thread which this thread is waiting on for a lock. */

    /*! Shared between thread.c and synch.c. */
    /**@{*/
    struct list_elem elem;              /*!< List element. */
    /**@}*/


#ifdef USERPROG
    /*! Owned by userprog/process.c. */
    /**@{*/
    uint32_t *pagedir;                  /*!< Page directory. */
    /**@{*/
#endif

    /*! Owned by thread.c. */
    /**@{*/
    unsigned magic;                     /* Detects stack overflow. */
    /**@}*/
};

We use niceness and recent_cpu so that we can store each threads corresponding
values. Let's us compute the updated priority.


static struct list ready_lists[PRI_MAX + 1];

We are using 64 lists so that we have a queue for each priority. This makes keeping track
of which thread is next in the priority easier.


int curr_load_avg = 0; // IN FIXED POINT FORMAT

We need to store the system wide variable that is the load_average. We are storing it in the printable form ie 100x the normal size and in the fixed point format. We can print it properly using the appropriate function. Functions that use this value know what format it is in and convert appropriately.
---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu     priority   thread
ticks  A    B    C    A   B   C   to run
-----  --   --   --   --  --  --   ------
 0     0    0    0    63  61  59    A 
 4     4    0    0    62  61  59    A
 8     8    0    0    61  61  59    A
12     12   0    0    60  61  59    B
16     12   4    0    60  60  59    B
20     12   8    0    60  59  59    A
24     16   8    0    59  59  59    A
28     20   8    0    58  59  59    B
32     20   12   0    58  58  59    C
36     20   12   4    58  58  58    A

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

What do we do in case of a tie? I chose to continue using the current thread
in case of a tie. If neither thread is current, we choose the thread with the lowest
niceness.
Our scheduler should choose the next thread based on the order in which they were 
enqueued.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

Recalc priorities disables interrupts. We need to do this because if the timer
ticks while this is going on, we might try to recalculate the priority again. This is problematic because we might update the priorities incorrectly and lose a set of timer ticks.


---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

If we could time how long recalculating takes to run, and/or determine exactly how fast interrupts can be fired, we might not need to disable interrupts because we could garuntee that no other interrupts would occur there.
I would also probably make the fixed point a real struct and/or implement floats because they seem useful to later parts of the kernel. It would make things easier to test and write in the future, which is likely worth more than the increase in speed and precision caused by being able to cancel terms.

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

Originally, I tried to multiply by 100 to hold on to the decimal terms
but couldn't determine how many orders of magntiude to use, so I went with
the 17.14 split explained in the assignment. I decided to implement it
by directly multiplying and dividing in the function calls. We store the 
fixed point versions. I chose this because I thought it would be faster
both to implement and to run. This also means we can cancel out terms
like redundant 14s in the numerator and denominator, which should also
boost our precision. 

              SURVEY QUESTIONS
              ================

Answering these questions is optional, but it will help us improve the
course in future years.  Feel free to tell us anything you want - these
questions are just to spur your thoughts.  Also, feel free to be completely
honest if there are issues with the assignment or the course - you won't be
penalized.  We can't fix things until we know about them.  :-)

>> In your opinion, was this assignment, or any of the parts of it, too
>> easy or too hard?  Did it take too long or too little time?

Took a long time, but that could also be because we started a bit late.

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Were there any parts of the assignment that you felt were unnecessarily
>> tedious or pointless?

Why are fixed points useful? Why don't we just multiply by 10^6 or something
and then divide later?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the instructor and/or TAs to more
>> effectively assist students, either for future quarters or the remaining
>> projects?

>> Any other comments?

